{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"63989eff0d164911a42e256e54955563","deepnote_cell_type":"text-cell-h1"},"source":"# Project 1: Classification","block_group":"fcf6ed90a1664987b79f3f5a68022881"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"db1acc9836c2412e858abfb4a4bf775c","deepnote_cell_type":"text-cell-p"},"source":"Equipo:","block_group":"48ce705bb1524bce8ea53a45e09fe866"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c33c8ce3f13e4570b50078c8bac26b4b","deepnote_cell_type":"text-cell-bullet"},"source":"- Jesús Valentín Niño Castañeda","block_group":"1527f0fca2dd4475a544c62d3079cbd7"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4c2cbbea56a143a08d776b651bfaa724","deepnote_cell_type":"text-cell-bullet"},"source":"- Angel Toshio Tribeño Hurtado","block_group":"9ab9f9b305e94023b93e3a2ef04fac2f"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7e37bf8e7b6540ad8b9f941813c4ea7b","deepnote_cell_type":"text-cell-bullet"},"source":"- Rafael Humberto Ramos Huamaní","block_group":"b04589eacd2b4d7bbfb21027859d32c4"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9bdccdbf69d346a1813484b3b119e000","deepnote_cell_type":"text-cell-bullet"},"source":"- Gabriel Vargas Urmeneta","block_group":"ef131009b5204232bd1f665025fe461a"},{"cell_type":"code","metadata":{"source_hash":"b4731589","execution_start":1759181563593,"execution_millis":45952,"execution_context_id":"86077cb8-b8bb-4eb6-aa7d-bac498369161","cell_id":"28386f12d85c401d8b1c8ca5d982872d","deepnote_cell_type":"code"},"source":"%pip install h5py pyts tsfresh xgboost","block_group":"756b941be96e4b2db1d0d526b8c8538d","execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: h5py in /root/venv/lib/python3.10/site-packages (3.14.0)\nCollecting pyts\n  Downloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tsfresh\n  Downloading tsfresh-0.21.1-py2.py3-none-any.whl (96 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting xgboost\n  Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in /root/venv/lib/python3.10/site-packages (from h5py) (1.25.2)\nCollecting scikit-learn>=1.2.0\n  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.8.1 in /root/venv/lib/python3.10/site-packages (from pyts) (1.9.3)\nCollecting numba>=0.55.2\n  Downloading numba-0.62.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /root/venv/lib/python3.10/site-packages (from pyts) (1.5.2)\nRequirement already satisfied: tqdm>=4.10.0 in /root/venv/lib/python3.10/site-packages (from tsfresh) (4.67.1)\nCollecting scipy>=1.8.1\n  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.9.1 in /root/venv/lib/python3.10/site-packages (from tsfresh) (2.32.5)\nCollecting statsmodels>=0.13\n  Downloading statsmodels-0.14.5-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pywavelets\n  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: cloudpickle in /root/venv/lib/python3.10/site-packages (from tsfresh) (2.2.1)\nCollecting patsy>=0.4.1\n  Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.9/232.9 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /root/venv/lib/python3.10/site-packages (from tsfresh) (2.1.4)\nCollecting stumpy>=1.7.2\n  Downloading stumpy-1.13.0-py3-none-any.whl (176 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.5/176.5 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12\n  Downloading nvidia_nccl_cu12-2.28.3-py3-none-manylinux_2_18_x86_64.whl (295.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.9/295.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting llvmlite<0.46,>=0.45.0dev0\n  Downloading llvmlite-0.45.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /root/venv/lib/python3.10/site-packages (from pandas>=0.25.0->tsfresh) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.1 in /root/venv/lib/python3.10/site-packages (from pandas>=0.25.0->tsfresh) (2025.2)\nRequirement already satisfied: pytz>=2020.1 in /root/venv/lib/python3.10/site-packages (from pandas>=0.25.0->tsfresh) (2025.2)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.10/site-packages (from requests>=2.9.1->tsfresh) (3.10)\nRequirement already satisfied: charset_normalizer<4,>=2 in /root/venv/lib/python3.10/site-packages (from requests>=2.9.1->tsfresh) (3.4.3)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.10/site-packages (from requests>=2.9.1->tsfresh) (2025.8.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.10/site-packages (from requests>=2.9.1->tsfresh) (2.5.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /root/venv/lib/python3.10/site-packages (from scikit-learn>=1.2.0->pyts) (3.6.0)\nRequirement already satisfied: packaging>=21.3 in /root/venv/lib/python3.10/site-packages (from statsmodels>=0.13->tsfresh) (25.0)\nRequirement already satisfied: six>=1.5 in /root/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.0->tsfresh) (1.17.0)\nInstalling collected packages: scipy, pywavelets, patsy, nvidia-nccl-cu12, llvmlite, xgboost, scikit-learn, numba, stumpy, statsmodels, pyts, tsfresh\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.9.3\n    Uninstalling scipy-1.9.3:\n      Successfully uninstalled scipy-1.9.3\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.1.3\n    Uninstalling scikit-learn-1.1.3:\n      Successfully uninstalled scikit-learn-1.1.3\nSuccessfully installed llvmlite-0.45.0 numba-0.62.1 nvidia-nccl-cu12-2.28.3 patsy-1.0.1 pyts-0.13.0 pywavelets-1.8.0 scikit-learn-1.7.2 scipy-1.15.3 statsmodels-0.14.5 stumpy-1.13.0 tsfresh-0.21.1 xgboost-3.0.5\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/5c935ff2-3072-4847-94b1-e3011416bd6e","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"29d82787","execution_start":1759125776883,"execution_millis":2017,"execution_context_id":"397ac21a-ebf7-47d6-9689-72ec3efc6e93","cell_id":"1202498fe4094a1791cc61e4342ba1b3","deepnote_cell_type":"code"},"source":"import h5py\n\nwith h5py.File(\"train.h5\", \"r\") as f:\n    print(\"Train keys:\", list(f.keys()))\n\nwith h5py.File(\"test.h5\", \"r\") as f:\n    print(\"Test keys:\", list(f.keys()))\n","block_group":"4fe6dbd0165a41d3b46192e36c396749","execution_count":2,"outputs":[{"name":"stdout","text":"Train keys: ['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z', 'y']\nTest keys: ['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z']\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/7ac8d8e0-67a5-4415-92b4-dc4fc8942582","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"97278cb9","execution_start":1759125779093,"execution_millis":780,"execution_context_id":"397ac21a-ebf7-47d6-9689-72ec3efc6e93","cell_id":"f6094d1c7a1243bc8329c5afe86630c2","deepnote_cell_type":"code"},"source":"import h5py\nimport numpy as np\n\n# Keys (sensors)\nSENSOR_KEYS = [\n    'body_acc_x', 'body_acc_y', 'body_acc_z',\n    'body_gyro_x', 'body_gyro_y', 'body_gyro_z',\n    'total_acc_x', 'total_acc_y', 'total_acc_z'\n]\n\ndef load_h5_file(path, include_labels=True):\n    with h5py.File(path, \"r\") as f:\n        # Stack 9 sensor signals along last axis\n        signals = [np.array(f[k]) for k in SENSOR_KEYS]\n        X = np.stack(signals, axis=-1)   # shape (n_samples, n_timestamps, 9)\n        y = np.array(f['y']).flatten() if include_labels and 'y' in f else None\n    return X, y\n\n# Load train/test\nX_train, y_train = load_h5_file(\"train.h5\", include_labels=True)\nX_test, _ = load_h5_file(\"test.h5\", include_labels=False)\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"X_test shape:\", X_test.shape)","block_group":"649283addcdd4ad8a0fd87d2c53f9ca2","execution_count":3,"outputs":[{"name":"stdout","text":"X_train shape: (7352, 128, 9)\ny_train shape: (7352,)\nX_test shape: (2947, 128, 9)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/5e3c5f87-5dfe-4223-be1d-2b7e95093cc0","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b3800cd24a62455d91ab0e40e67dc060","deepnote_cell_type":"text-cell-h2"},"source":"## TsFresh","block_group":"3a2d549f8a44486388d8d7397c3bdb47"},{"cell_type":"code","metadata":{"source_hash":"e588ec68","execution_start":1759127200937,"execution_millis":131863,"execution_context_id":"c03445df-438b-4fa1-95cb-5fe105528f48","cell_id":"d55e3fe11df04fa2abf85676f8b67368","deepnote_cell_type":"code"},"source":"import h5py\nimport numpy as np\nimport pandas as pd\nfrom tsfresh import extract_features\nfrom tsfresh.feature_extraction import MinimalFCParameters\n\n# --- Load HAR data from .h5 ---\nSENSOR_KEYS = [\n    'body_acc_x', 'body_acc_y', 'body_acc_z',\n    'body_gyro_x', 'body_gyro_y', 'body_gyro_z',\n    'total_acc_x', 'total_acc_y', 'total_acc_z'\n]\n\ndef load_h5_file(path, include_labels=True):\n    with h5py.File(path, \"r\") as f:\n        signals = [np.array(f[k]) for k in SENSOR_KEYS]\n        X = np.stack(signals, axis=-1)  # (n_samples, n_timestamps, 9)\n        y = np.array(f['y']).flatten() if include_labels and 'y' in f else None\n    return X, y\n\nX_train, y_train = load_h5_file(\"train.h5\", include_labels=True)\nX_test, _ = load_h5_file(\"test.h5\", include_labels=False)\n\n# --- Convert to long format for tsfresh ---\ndef to_long_dataframe(X):\n    n_samples, n_timestamps, n_features = X.shape\n    records = []\n    for sample in range(n_samples):\n        for feature in range(n_features):\n            for t in range(n_timestamps):\n                records.append({\n                    \"id\": sample,\n                    \"time\": t,\n                    \"kind\": f\"f{feature}\",\n                    \"value\": X[sample, t, feature]\n                })\n    return pd.DataFrame(records)\n\ndf_train = to_long_dataframe(X_train)\ndf_test  = to_long_dataframe(X_test)\n\n# --- Feature extraction ---\nfeatures_train = extract_features(\n    df_train,\n    column_id=\"id\",\n    column_sort=\"time\",\n    column_kind=\"kind\",\n    column_value=\"value\",\n    default_fc_parameters=MinimalFCParameters(),\n    n_jobs=1\n)\n\nfeatures_test = extract_features(\n    df_test,\n    column_id=\"id\",\n    column_sort=\"time\",\n    column_kind=\"kind\",\n    column_value=\"value\",\n    default_fc_parameters=MinimalFCParameters(),\n    n_jobs=1\n)\n\n# --- Save results ---\nfeatures_train[\"activity\"] = y_train  # attach labels for later training\nfeatures_train.to_csv(\"features_tsfresh_train.csv\", index=False)\nfeatures_test.to_csv(\"features_tsfresh_test.csv\", index=False)\n\nprint(\"tsfresh features saved to CSV\")","block_group":"55f5355325634966b72a44b79ffa2f86","execution_count":4,"outputs":[{"name":"stderr","text":"Feature Extraction: 100%|██████████| 66168/66168 [00:48<00:00, 1372.69it/s]\nFeature Extraction: 100%|██████████| 26523/26523 [00:19<00:00, 1360.47it/s]\ntsfresh features saved to CSV\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/207051b0-57ca-400b-9a5e-adcb13ca9519","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c10ff764b5084272840b039547b10232","deepnote_cell_type":"text-cell-h2"},"source":"## PyTS","block_group":"14f7dfcd61d047e28e548fa69a7f4bed"},{"cell_type":"code","metadata":{"source_hash":"f095f859","execution_start":1759126504093,"execution_millis":33050,"execution_context_id":"8c913bf7-c9a1-4d64-8fa9-f5fd28831d36","cell_id":"27c0bca9e9fa434086040526cd857669","deepnote_cell_type":"code"},"source":"import h5py\nimport numpy as np\nfrom pyts.image import RecurrencePlot\n\n# --- Load HAR dataset ---\nSENSOR_KEYS = [\n    'body_acc_x', 'body_acc_y', 'body_acc_z',\n    'body_gyro_x', 'body_gyro_y', 'body_gyro_z',\n    'total_acc_x', 'total_acc_y', 'total_acc_z'\n]\n\ndef load_h5_file(path, include_labels=True):\n    with h5py.File(path, \"r\") as f:\n        signals = [np.array(f[k]) for k in SENSOR_KEYS]\n        X = np.stack(signals, axis=-1)  # (n_samples, 128, 9)\n        y = np.array(f['y']).flatten() if include_labels and 'y' in f else None\n    return X, y\n\nX_train, y_train = load_h5_file(\"train.h5\", include_labels=True)\nX_test, _ = load_h5_file(\"test.h5\", include_labels=False)\n\n# --- Pick one channel (example: total_acc_x = index 6) ---\nX_train_channel = X_train[:, :, 6]\nX_test_channel  = X_test[:, :, 6]\n\n# --- Batch processing with RecurrencePlot ---\ndef pyts_in_batches(X, batch_size=500, filename=\"output.npz\"):\n    rp = RecurrencePlot(threshold=\"point\", percentage=20)\n    n_samples = X.shape[0]\n    \n    with open(filename, \"wb\") as f:  # placeholder open, actual save with np.savez_compressed later\n        pass\n    \n    batches = []\n    for start in range(0, n_samples, batch_size):\n        end = min(start + batch_size, n_samples)\n        print(f\"Processing {start}:{end}/{n_samples}\")\n        \n        batch = rp.fit_transform(X[start:end])\n        batch = batch.astype(np.float32)  # save memory\n        batches.append(batch)\n    \n    X_rp = np.vstack(batches)\n    np.savez_compressed(filename, X_rp=X_rp)\n    return X_rp\n\n# --- Process and save ---\nX_rp_train = pyts_in_batches(X_train_channel, batch_size=500, filename=\"features_pyts_train.npz\")\nnp.savez_compressed(\"features_pyts_train.npz\", X_rp_train=X_rp_train, y_train=y_train)\n\nX_rp_test = pyts_in_batches(X_test_channel, batch_size=500, filename=\"features_pyts_test.npz\")\nnp.savez_compressed(\"features_pyts_test.npz\", X_rp_test=X_rp_test)\n\nprint(\"PyTS features extracted and saved\")","block_group":"6072a7370a0e494397f40012cb8716e6","execution_count":4,"outputs":[{"name":"stdout","text":"Processing 0:500/7352\nProcessing 500:1000/7352\nProcessing 1000:1500/7352\nProcessing 1500:2000/7352\nProcessing 2000:2500/7352\nProcessing 2500:3000/7352\nProcessing 3000:3500/7352\nProcessing 3500:4000/7352\nProcessing 4000:4500/7352\nProcessing 4500:5000/7352\nProcessing 5000:5500/7352\nProcessing 5500:6000/7352\nProcessing 6000:6500/7352\nProcessing 6500:7000/7352\nProcessing 7000:7352/7352\nProcessing 0:500/2947\nProcessing 500:1000/2947\nProcessing 1000:1500/2947\nProcessing 1500:2000/2947\nProcessing 2000:2500/2947\nProcessing 2500:2947/2947\nPyTS features extracted and saved\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/df3c4eba-13ea-417a-9bd2-80d37249c1bb","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"80bb70e411bf45529d78764942cd85da","deepnote_cell_type":"text-cell-h2"},"source":"## Preliminary Testing","block_group":"49399aafeb344d878d91097ce84c9ddc"},{"cell_type":"code","metadata":{"source_hash":"adf5fefe","execution_start":1759181628334,"execution_millis":2653,"execution_context_id":"86077cb8-b8bb-4eb6-aa7d-bac498369161","cell_id":"ffbf3585200f4076b90900c155b413b2","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\n\n# === TsFresh data ===\nfeatures_train = pd.read_csv(\"features_tsfresh_train.csv\")\nfeatures_test  = pd.read_csv(\"features_tsfresh_test.csv\")\n\n# Separate labels\ny_train = features_train[\"activity\"].astype(int) - 1\nX_train = features_train.drop(columns=[\"activity\"])\nX_test  = features_test\n\n# === PyTS data ===\ndata_train = np.load(\"features_pyts_train.npz\")\nX_rp_train = data_train[\"X_rp_train\"]\ny_rp_train = data_train[\"y_train\"].astype(int) - 1\n\ndata_test = np.load(\"features_pyts_test.npz\")\nX_rp_test = data_test[\"X_rp_test\"]\n\n# Flatten images for sklearn classifiers\nn_samples, h, w = X_rp_train.shape\nX_rp_train = X_rp_train.reshape(n_samples, -1)\nX_rp_test  = X_rp_test.reshape(X_rp_test.shape[0], -1)","block_group":"8e55496ee04e4b19bcfe88572d0d2767","execution_count":4,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"342596e7","execution_start":1759181631044,"execution_millis":78370,"execution_context_id":"86077cb8-b8bb-4eb6-aa7d-bac498369161","cell_id":"a1f26e19c32348caa780b964f84fa68e","deepnote_cell_type":"code"},"source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nprint(\"=== Benchmarking Multiple Models with TsFresh data ===\")\n\n# --- Split train into train/val ---\nX_tr, X_val, y_tr, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=42\n)\n\n# --- Escalar datos para modelos sensibles (LogReg, SVM, KNN, NB) ---\nscaler = StandardScaler()\nX_tr_scaled = scaler.fit_transform(X_tr)\nX_val_scaled = scaler.transform(X_val)\n\n# --- Definir modelos ---\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n    \"Naive Bayes\": GaussianNB(),\n    \"Linear SVM\": LinearSVC(max_iter=2000),\n    \"RBF SVM\": SVC(kernel=\"rbf\"),\n    \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n    \"XGBoost\": XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n}\n\n# --- Entrenar y evaluar ---\nresults = {}\nfor name, model in models.items():\n    print(f\"\\n>>> {name}\")\n    \n    # Algunos modelos necesitan datos escalados\n    if name in [\"Logistic Regression\", \"Naive Bayes\", \"Linear SVM\", \"RBF SVM\", \"KNN (k=5)\"]:\n        model.fit(X_tr_scaled, y_tr)\n        y_pred = model.predict(X_val_scaled)\n    else:\n        model.fit(X_tr, y_tr)\n        y_pred = model.predict(X_val)\n    \n    acc = accuracy_score(y_val, y_pred)\n    f1 = f1_score(y_val, y_pred, average=\"weighted\")\n    cm = confusion_matrix(y_val, y_pred)\n    \n    results[name] = {\"Accuracy\": acc, \"F1\": f1}\n    \n    print(\"Accuracy:\", acc)\n    print(\"F1 Score:\", f1)\n    print(\"Confusion Matrix:\\n\", cm)\n    # Opcional: reporte detallado\n    # print(classification_report(y_val, y_pred))\n","block_group":"bbc5d535b4c047d298e4029a18f41a8a","execution_count":5,"outputs":[{"name":"stdout","text":"=== Benchmarking Multiple Models with TsFresh data ===\n\n>>> Logistic Regression\nAccuracy: 0.938137321549966\nF1 Score: 0.9381939562274736\nConfusion Matrix:\n [[236  10   1   0   0   0]\n [  7 191   2   0   0   0]\n [ 10   4 192   0   0   0]\n [  0   0   0 235  27   0]\n [  0   0   0  30 246   0]\n [  0   0   0   0   0 280]]\n\n>>> Decision Tree\nAccuracy: 0.9401767505098573\nF1 Score: 0.9401592486401132\nConfusion Matrix:\n [[226  14   6   0   1   0]\n [ 20 173   7   0   0   0]\n [ 11   8 187   0   0   0]\n [  0   0   0 245  17   0]\n [  0   0   0   4 272   0]\n [  0   0   0   0   0 280]]\n\n>>> Random Forest\nAccuracy: 0.9789259007477906\nF1 Score: 0.9789219276974194\nConfusion Matrix:\n [[244   2   1   0   0   0]\n [  2 196   2   0   0   0]\n [  4   2 200   0   0   0]\n [  0   0   0 253   9   0]\n [  0   0   0   9 267   0]\n [  0   0   0   0   0 280]]\n\n>>> Naive Bayes\nAccuracy: 0.8103331067301156\nF1 Score: 0.8021684334964048\nConfusion Matrix:\n [[208  28  11   0   0   0]\n [ 37 151  12   0   0   0]\n [ 25   7 174   0   0   0]\n [  1   3   0 117 138   3]\n [  0   3   0  10 263   0]\n [  0   1   0   0   0 279]]\n\n>>> Linear SVM\nAccuracy: 0.9422161794697484\nF1 Score: 0.942269699301854\nConfusion Matrix:\n [[234  11   2   0   0   0]\n [  5 193   2   0   0   0]\n [  9   3 193   1   0   0]\n [  0   0   0 238  24   0]\n [  0   0   0  28 248   0]\n [  0   0   0   0   0 280]]\n\n>>> RBF SVM\nAccuracy: 0.9435757987763427\nF1 Score: 0.9436316335521616\nConfusion Matrix:\n [[232  15   0   0   0   0]\n [  3 196   1   0   0   0]\n [  5   2 198   0   0   1]\n [  0   0   0 242  20   0]\n [  0   0   0  36 240   0]\n [  0   0   0   0   0 280]]\n\n>>> KNN (k=5)\nAccuracy: 0.9524133242692047\nF1 Score: 0.9524587063084201\nConfusion Matrix:\n [[243   4   0   0   0   0]\n [ 13 184   3   0   0   0]\n [ 11   4 191   0   0   0]\n [  0   0   0 246  16   0]\n [  0   0   0  18 258   0]\n [  0   0   0   1   0 279]]\n\n>>> XGBoost\nAccuracy: 0.9877634262406526\nF1 Score: 0.9877603444267434\nConfusion Matrix:\n [[246   1   0   0   0   0]\n [  2 198   0   0   0   0]\n [  3   2 201   0   0   0]\n [  0   0   0 254   8   0]\n [  0   0   0   2 274   0]\n [  0   0   0   0   0 280]]\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/eab1a8ad-3486-44b0-ba2d-b2d2ab67f2a5","content_dependencies":null},{"cell_type":"code","metadata":{"allow_embed":false,"source_hash":"cebc9337","execution_start":1759181709489,"execution_millis":20479,"execution_context_id":"86077cb8-b8bb-4eb6-aa7d-bac498369161","cell_id":"27d78c5595f24db5936ac6a264aed2f2","deepnote_cell_type":"code"},"source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nprint(\"=== Benchmarking Multiple Models with PyTS data ===\")\n\n# --- Split train into train/val ---\nX_tr, X_val, y_tr, y_val = train_test_split(\n    X_rp_train, y_rp_train, test_size=0.2, random_state=42\n)\n\n# --- Escalar datos para modelos sensibles (LogReg, SVM, KNN, NB) ---\nscaler = StandardScaler()\nX_tr_scaled = scaler.fit_transform(X_tr)\nX_val_scaled = scaler.transform(X_val)\n\n# --- Definir modelos ---\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n    \"Naive Bayes\": GaussianNB(),\n    \"Linear SVM\": LinearSVC(max_iter=2000),\n    \"RBF SVM\": SVC(kernel=\"rbf\"),\n    \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n    \"XGBoost\": XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n}\n\n# --- Entrenar y evaluar ---\nresults = {}\nfor name, model in models.items():\n    print(f\"\\n>>> {name}\")\n    \n    # Algunos modelos necesitan datos escalados\n    if name in [\"Logistic Regression\", \"Naive Bayes\", \"Linear SVM\", \"RBF SVM\", \"KNN (k=5)\"]:\n        model.fit(X_tr_scaled, y_tr)\n        y_pred = model.predict(X_val_scaled)\n    else:\n        model.fit(X_tr, y_tr)\n        y_pred = model.predict(X_val)\n    \n    acc = accuracy_score(y_val, y_pred)\n    f1 = f1_score(y_val, y_pred, average=\"weighted\")\n    cm = confusion_matrix(y_val, y_pred)\n    \n    results[name] = {\"Accuracy\": acc, \"F1\": f1}\n    \n    print(\"Accuracy:\", acc)\n    print(\"F1 Score:\", f1)\n    print(\"Confusion Matrix:\\n\", cm)\n    # Opcional: reporte detallado\n    # print(classification_report(y_val, y_pred))\n","block_group":"fd4406a4d3924dd6b010303b0ba411c0","execution_count":null,"outputs":[{"name":"stdout","text":"=== Benchmarking Multiple Models with PyTS data ===\n\n>>> Logistic Regression\nAccuracy: 0.504418762746431\nF1 Score: 0.5018065264523589\nConfusion Matrix:\n [[170  29  47   0   1   0]\n [ 37 119  41   0   0   3]\n [ 37  47 104  10   5   3]\n [  2   2   3  75 113  67]\n [  3   1   5  74 129  64]\n [  5   4   1  52  73 145]]\n\n>>> Decision Tree\nAccuracy: 0.2610469068660775\nF1 Score: 0.26108175277468004\nConfusion Matrix:\n [[84 46 42 22 29 24]\n [47 47 41 16 17 32]\n [42 45 44 30 20 25]\n [21 26 29 63 64 59]\n [32 30 22 66 70 56]\n [34 22 39 45 64 76]]\n\n>>> Random Forest\nAccuracy: 0.469068660774983\nF1 Score: 0.4614348757657078\nConfusion Matrix:\n [[175  28  21   5  13   5]\n [ 66 101   7   7   3  16]\n [ 67  32  48  13  28  18]\n [  2   0   0  81 117  62]\n [  0   2   1  88 150  35]\n [  1   0   1  54  89 135]]\n\n>>> Naive Bayes\nAccuracy: 0.42895989123045547\nF1 Score: 0.42940807607608267\nConfusion Matrix:\n [[115  60  64   2   6   0]\n [ 39 100  36   6  17   2]\n [ 43  39  72  12  40   0]\n [  0   0   0  65 162  35]\n [  0   2   1  78 169  26]\n [  0   0   2  58 110 110]]\n\n>>> Linear SVM\nAccuracy: 0.4004078857919782\nF1 Score: 0.39758757513189136\nConfusion Matrix:\n [[127  35  45  15  17   8]\n [ 33 107  30   5   6  19]\n [ 36  46  66  28  20  10]\n [ 15   8  16  68  96  59]\n [ 18  12  22  76  83  65]\n [ 15  20   7  39  61 138]]\n\n>>> RBF SVM\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/8f4ce3c6-c6ec-424b-9f92-0269f386256b","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=9cf3d34f-aa4d-4d65-a77f-229ed288b911' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"720790fa37304849b6c3457771488ff4"}}